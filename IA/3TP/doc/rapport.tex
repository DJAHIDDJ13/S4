\documentclass {article}

\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage{listings}
\usepackage{color}
\usepackage{float}

\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}

\lstset{frame=tb,
    language=C,
    aboveskip=3mm,
    belowskip=3mm,
    showstringspaces=false,
    columns=flexible,
    basicstyle={\small\ttfamily},
    numbers=left,
    numberstyle=\tiny\color{gray},
    keywordstyle=\color{blue},
    commentstyle=\color{dkgreen},
    stringstyle=\color{mauve},
    breaklines=true,
    breakatwhitespace=true,
    tabsize=3
}


\title{TP4 IA: Perceptron}
\author{ABDELMOUMENE Djahid}

\begin{document}
\maketitle

\section{Questions préliminaires}
Pour la reconnaissance de deux classes A et C il nou faudra 20 neurones
d'entrées pour le pixels de motif, et 2 neurone de sortie pour chaque classe.
\begin{figure}[H]
   \centering
   \includegraphics[height=20em]{ACrn.png}
   \caption{Schéma de réseau neurone pour classification de A et C}
\end{figure}

Structure de réseau de neurone:
\begin{lstlisting}
typedef struct neurone {
   float *weight;              // tableau de coefficients 
   float (*activation)(float); // la fonction d'activation
   float out;                  // la valeur de sortie
} NEURONE;

typedef struct network {
   int num_layers;   // le nombre de couches
   NEURONE **layers; // Les neurones d'entrees et de sortie
   float *biases;    // Un biais par couche
   int *sizes;       // les tailles de chaque couche
} NETWORK;
\end{lstlisting}

Les poids de réseau neurones sont initialisé avec des valeurs aléatoires entre
0 et 1, les biais est mis à 0.\\

La propagation de neurone de sortie $j$ se fait par la formule suivant:
\begin{equation}
   \sum^{input\_size}_{i=1} f(W_{i j} * e_{i} - \theta_{1})
\end{equation}

Pour l'apprentisage, on met à jour les coefficient comme suit:
\begin{equation}
   W_{ij}(t+1) = W_{ij} + \epsilon * (Sd^c(i) - Xout_{i}(i)) * Xin_{i}(t)
\end{equation}

Et pour le mise à jour de biais:
\begin{equation}
   \theta_{l}(t+1) = \theta_{l}(t) + \sum_{i=1}^{input\_size}\epsilon * Xin_{i}(t)
\end{equation}

L'apprentissage s'arrête lorsqu'on atteint un niveau d'erreur acceptable
prédefini.

\section{Question de compréhension}
Le processus d'apprentissage consiste à minimiser une fonction d'erreur à un
certain minimum local, et pour le cas des deux lettres, le réseau fonctionne
comme un modèle de régression linéaire.\\

En cas de translation ou rotation le réseau se généralise correctement et
parvient à classer les deux lettres.\\

Pour la reconnaissance de lettres de l'alphabet le réseau neurone aura 20
neurones d'entrées (pour chaque pixel), et 26 neurone de sortie pour chaque
lettre de l'alphabet
\begin{figure}[H]
   \centering
   \includegraphics[height=20em]{AZrn.png}
   \caption{Schéma de réseau neurone pour classification de lettres d'alphabet}
\end{figure}

\end{document}
